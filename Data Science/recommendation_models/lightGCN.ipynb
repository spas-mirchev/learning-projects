{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, metrics, preprocessing\n",
    "import copy\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, Tensor\n",
    "\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.typing import Adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  item_id  rating  timestamp\n",
      "0      196      242       3  881250949\n",
      "1      186      302       3  891717742\n",
      "2       22      377       1  878887116\n",
      "3      244       51       2  880606923\n",
      "4      166      346       1  886397596\n",
      "1682\n",
      "943\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>462.48475</td>\n",
       "      <td>425.530130</td>\n",
       "      <td>3.529860</td>\n",
       "      <td>8.835289e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>266.61442</td>\n",
       "      <td>330.798356</td>\n",
       "      <td>1.125674</td>\n",
       "      <td>5.343856e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.747247e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>254.00000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.794487e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>447.00000</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.828269e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>682.00000</td>\n",
       "      <td>631.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.882600e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>943.00000</td>\n",
       "      <td>1682.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.932866e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id        item_id         rating     timestamp\n",
       "count  100000.00000  100000.000000  100000.000000  1.000000e+05\n",
       "mean      462.48475     425.530130       3.529860  8.835289e+08\n",
       "std       266.61442     330.798356       1.125674  5.343856e+06\n",
       "min         1.00000       1.000000       1.000000  8.747247e+08\n",
       "25%       254.00000     175.000000       3.000000  8.794487e+08\n",
       "50%       447.00000     322.000000       4.000000  8.828269e+08\n",
       "75%       682.00000     631.000000       4.000000  8.882600e+08\n",
       "max       943.00000    1682.000000       5.000000  8.932866e+08"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_path = \"/home/evgeniya/Documents/code/reco/csv/u.data\"\n",
    "\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "rating_df = pd.read_csv((rating_path),  sep='\\t',  names=names)\n",
    "print(rating_df.head())\n",
    "\n",
    "print(len(rating_df['item_id'].unique()))\n",
    "print(len(rating_df['user_id'].unique()))\n",
    "\n",
    "rating_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform encoding preprocessing to ensure that user_id and item_id are both \n",
    "# in the range of [0, unique_count] so it won't cause out of bound issue when indexing embeddings\n",
    "lbl_user = preprocessing.LabelEncoder()\n",
    "lbl_movie = preprocessing.LabelEncoder()\n",
    "\n",
    "rating_df.user_id = lbl_user.fit_transform(rating_df.user_id.values)\n",
    "rating_df.item_id = lbl_movie.fit_transform(rating_df.item_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942\n",
      "1681\n"
     ]
    }
   ],
   "source": [
    "print(rating_df.user_id.max())\n",
    "print(rating_df.item_id.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load edges between users and movies\n",
    "def load_edge_csv(df, \n",
    "                  src_index_col, \n",
    "                  dst_index_col, \n",
    "                  link_index_col, \n",
    "                  rating_threshold=3):\n",
    "    \"\"\"Loads csv containing edges between users and items\n",
    "\n",
    "    Args:\n",
    "        src_index_col (str): column name of users\n",
    "        dst_index_col (str): column name of items\n",
    "        link_index_col (str): column name of user item interaction\n",
    "        rating_threshold (int, optional): Threshold to determine positivity of edge. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        list of list: edge_index -- 2 by N matrix containing the node ids of N user-item edges\n",
    "        N here is the number of interactions\n",
    "    \"\"\"\n",
    "    \n",
    "    edge_index = None\n",
    "    \n",
    "    # Constructing COO format edge_index from input rating events\n",
    "    \n",
    "    # get user_ids from rating events in the order of occurance\n",
    "    src = [user_id for user_id in  df['user_id']]    \n",
    "    # get movie_id from rating events in the order of occurance\n",
    "    dst = [(movie_id) for movie_id in df['item_id']]\n",
    "\n",
    "    # apply rating threshold\n",
    "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n",
    "\n",
    "    edge_index = [[], []]\n",
    "    for i in range(edge_attr.shape[0]):\n",
    "        if edge_attr[i]:\n",
    "            edge_index[0].append(src[i])\n",
    "            edge_index[1].append(dst[i])\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = load_edge_csv(\n",
    "    rating_df,\n",
    "    src_index_col='user_id',\n",
    "    dst_index_col='item_id',\n",
    "    link_index_col='rating',\n",
    "    rating_threshold=3, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 x 82520\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(edge_index)} x {len(edge_index[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[195, 185, 297,  ..., 879, 715,  11],\n",
      "        [241, 301, 473,  ..., 475, 203, 202]])\n",
      "torch.Size([2, 82520])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82520"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to tensor\n",
    "# We use LongTensor here because the .propagate() method in the model needs either LongTensor or SparseTensor\n",
    "edge_index = torch.LongTensor(edge_index) \n",
    "print(edge_index)\n",
    "print(edge_index.size())\n",
    "edge_index.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this is the total num_users and num_movies before we apply the rating_threshold\n",
    "num_users = len(rating_df['user_id'].unique())\n",
    "num_items = len(rating_df['item_id'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_interactions = edge_index.shape[1]\n",
    "\n",
    "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
    "all_indices = [i for i in range(num_interactions)]\n",
    "\n",
    "train_indices, test_indices = train_test_split(all_indices, \n",
    "                                               test_size=0.2, \n",
    "                                               random_state=1)\n",
    "\n",
    "val_indices, test_indices = train_test_split(test_indices, \n",
    "                                             test_size=0.5, \n",
    "                                             random_state=1)\n",
    "\n",
    "train_edge_index = edge_index[:, train_indices]\n",
    "val_edge_index = edge_index[:, val_indices]\n",
    "test_edge_index = edge_index[:, test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_users 943, num_movies 1682, num_interactions 82520\n",
      "train_edge_index tensor([[261, 118, 408,  ..., 183,  31, 928],\n",
      "        [784, 740, 381,  ..., 402, 249, 653]])\n",
      "train_edge_index 66016\n",
      "2625\n",
      "torch.Size([943])\n",
      "torch.Size([1545])\n"
     ]
    }
   ],
   "source": [
    "print(f\"num_users {num_users}, num_movies {num_items}, num_interactions {num_interactions}\")\n",
    "print(f\"train_edge_index {train_edge_index}\")\n",
    "print(f\"train_edge_index {len(train_edge_index[0])}\")\n",
    "print((num_users + num_items))\n",
    "print(torch.unique(train_edge_index[0]).size())\n",
    "print(torch.unique(train_edge_index[1]).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_r_mat_edge_index_to_adj_mat_edge_index(input_edge_index):\n",
    "    R = torch.zeros((num_users, num_items))\n",
    "    for i in range(len(input_edge_index[0])):\n",
    "        row_idx = input_edge_index[0][i]\n",
    "        col_idx = input_edge_index[1][i]\n",
    "        R[row_idx][col_idx] = 1\n",
    "\n",
    "    R_transpose = torch.transpose(R, 0, 1)\n",
    "    adj_mat = torch.zeros((num_users + num_items , num_users + num_items))\n",
    "    adj_mat[: num_users, num_users :] = R.clone()\n",
    "    adj_mat[num_users :, : num_users] = R_transpose.clone()\n",
    "    adj_mat_coo = adj_mat.to_sparse_coo()\n",
    "    adj_mat_coo = adj_mat_coo.indices()\n",
    "    return adj_mat_coo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index):\n",
    "    sparse_input_edge_index = SparseTensor(row=input_edge_index[0], \n",
    "                                           col=input_edge_index[1], \n",
    "                                           sparse_sizes=((num_users + num_items), num_users + num_items))\n",
    "    adj_mat = sparse_input_edge_index.to_dense()\n",
    "    interact_mat = adj_mat[: num_users, num_users :]\n",
    "    r_mat_edge_index = interact_mat.to_sparse_coo().indices()\n",
    "    return r_mat_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 66016])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from r_mat (interaction matrix) edge index to adjescency matrix's edge index \n",
    "# so we can feed it to model\n",
    "train_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(train_edge_index)\n",
    "val_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(val_edge_index)\n",
    "test_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(test_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ..., 2617, 2619, 2624],\n",
      "        [ 943,  944,  946,  ...,  850,  853,  915]])\n",
      "torch.Size([2, 132032])\n",
      "tensor([[   0,    0,    0,  ..., 2592, 2594, 2615],\n",
      "        [ 945,  956,  974,  ...,  654,  661,  834]])\n",
      "torch.Size([2, 16504])\n",
      "tensor([[   0,    0,    0,  ..., 2600, 2621, 2623],\n",
      "        [ 948,  959,  960,  ...,  893,  862,  895]])\n",
      "torch.Size([2, 16504])\n"
     ]
    }
   ],
   "source": [
    "print(train_edge_index)\n",
    "print(train_edge_index.size())\n",
    "print(val_edge_index)\n",
    "print(val_edge_index.size())\n",
    "print(test_edge_index)\n",
    "print(test_edge_index.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,  ..., 2617, 2619, 2624],\n",
      "        [ 943,  944,  946,  ...,  850,  853,  915]])\n",
      "torch.Size([2, 132032])\n",
      "tensor([[   0,    0,    0,  ..., 2592, 2594, 2615],\n",
      "        [ 945,  956,  974,  ...,  654,  661,  834]])\n",
      "torch.Size([2, 16504])\n",
      "tensor([[   0,    0,    0,  ..., 2600, 2621, 2623],\n",
      "        [ 948,  959,  960,  ...,  893,  862,  895]])\n",
      "torch.Size([2, 16504])\n"
     ]
    }
   ],
   "source": [
    "print(train_edge_index)\n",
    "print(train_edge_index.size())\n",
    "print(val_edge_index)\n",
    "print(val_edge_index.size())\n",
    "print(test_edge_index)\n",
    "print(test_edge_index.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for training and compute BPR loss\n",
    "# since this is a self-supervised learning, we are relying on the graph structure itself and \n",
    "# we don't have label other than the graph structure so we need to the folloing function\n",
    "# which random samples a mini-batch of positive and negative samples\n",
    "def sample_mini_batch(batch_size, edge_index):\n",
    "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): minibatch size\n",
    "        edge_index (torch.Tensor): 2 by N list of edges\n",
    "\n",
    "    Returns:\n",
    "        tuple: user indices, positive item indices, negative item indices\n",
    "    \"\"\"\n",
    "    # structured_negative_sampling is a pyG library\n",
    "    # Samples a negative edge :obj:`(i,k)` for every positive edge\n",
    "    # :obj:`(i,j)` in the graph given by :attr:`edge_index`, and returns it as a\n",
    "    # tuple of the form :obj:`(i,j,k)`.\n",
    "    #\n",
    "    #         >>> edge_index = torch.as_tensor([[0, 0, 1, 2],\n",
    "    #         ...                               [0, 1, 2, 3]])\n",
    "    #         >>> structured_negative_sampling(edge_index)\n",
    "    #         (tensor([0, 0, 1, 2]), tensor([0, 1, 2, 3]), tensor([2, 3, 0, 2]))\n",
    "    edges = structured_negative_sampling(edge_index)\n",
    "    \n",
    "    # 3 x edge_index_len\n",
    "    edges = torch.stack(edges, dim=0)\n",
    "    \n",
    "    # here is whhen we actually perform the batch sampe\n",
    "    # Return a k sized list of population elements chosen with replacement.\n",
    "    indices = random.choices([i for i in range(edges[0].shape[0])], k=batch_size)\n",
    "    \n",
    "    batch = edges[:, indices]\n",
    "    \n",
    "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
    "    return user_indices, pos_item_indices, neg_item_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines LightGCN model \n",
    "class LightGCN(MessagePassing):\n",
    "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_users, \n",
    "                 num_items, \n",
    "                 embedding_dim=64, # define the embding vector length for each node\n",
    "                 K=3, \n",
    "                 add_self_loops=False):\n",
    "        \"\"\"Initializes LightGCN Model\n",
    "\n",
    "        Args:\n",
    "            num_users (int): Number of users\n",
    "            num_items (int): Number of items\n",
    "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
    "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
    "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.K = K\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        # define user and item embedding for direct look up. \n",
    "        # embedding dimension: num_user/num_item x embedding_dim\n",
    "        \n",
    "        self.users_emb = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
    "        \n",
    "        self.items_emb = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
    "\n",
    "        # \"Fills the input Tensor with values drawn from the normal distribution\"\n",
    "        # according to LightGCN paper, this gives better performance\n",
    "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
    "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
    "\n",
    "    def forward(self, edge_index: Tensor):\n",
    "        \"\"\"Forward propagation of LightGCN Model.\n",
    "\n",
    "        Args:\n",
    "            edge_index (SparseTensor): adjacency matrix\n",
    "\n",
    "        Returns:\n",
    "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "            compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
    "            \\tilde_A = D^(-1/2) * A * D^(-1/2)    according to LightGCN paper\n",
    "        \n",
    "            this is essentially a metrix operation way to get 1/ (sqrt(n_neighbors_i) * sqrt(n_neighbors_j))\n",
    "\n",
    "        \n",
    "            if your original edge_index look like\n",
    "            tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
    "                    [   0,    2,    5,  ..., 9444, 9445, 9485]])\n",
    "                    \n",
    "…        # \n",
    "        # elementwise multiply by the symmetrically norm. So it's essentiall what formula 7 in LightGCN\n",
    "        # paper does but here we are using edge_index rather than Adj Matrix\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "layers = 3    \n",
    "model = LightGCN(num_users=num_users, \n",
    "                 num_items=num_movies, \n",
    "                 K=layers)                \n",
    "                    torch.Size([2, 99466])\n",
    "                    \n",
    "            then this will output: \n",
    "                (\n",
    "                 tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
    "                         [   0,    2,    5,  ..., 9444, 9445, 9485]]), \n",
    "                 tensor([0.0047, 0.0096, 0.0068,  ..., 0.0592, 0.0459, 0.1325])\n",
    "                 )\n",
    "                 \n",
    "              where edge_index_norm[0] is just the original edge_index\n",
    "              \n",
    "              and edge_index_norm[1] is the symmetrically normalization term. \n",
    "              \n",
    "            under the hood it's basically doing\n",
    "                def compute_gcn_norm(edge_index, emb):\n",
    "                    emb = emb.weight\n",
    "                    from_, to_ = edge_index\n",
    "                    deg = degree(to_, emb.size(0), dtype=emb.dtype)\n",
    "                    deg_inv_sqrt = deg.pow(-0.5)\n",
    "                    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "                    norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n",
    "\n",
    "                    return norm\n",
    "                 \n",
    "                \n",
    "        \"\"\"\n",
    "        edge_index_norm = gcn_norm(edge_index=edge_index, \n",
    "                                   add_self_loops=self.add_self_loops)\n",
    "\n",
    "        # concat the user_emb and item_emb as the layer0 embing matrix\n",
    "        # size will be (n_users + n_items) x emb_vector_len.   e.g: 10334 x 64\n",
    "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
    "\n",
    "        embs = [emb_0] # save the layer0 emb to the embs list\n",
    "        \n",
    "        # emb_k is the emb that we are actually going to push it through the graph layers\n",
    "        # as described in lightGCN paper formula 7\n",
    "        emb_k = emb_0 \n",
    "\n",
    "        # push the embedding of all users and items through the Graph Model K times.\n",
    "        # K here is the number of layers\n",
    "        for i in range(self.K):\n",
    "            emb_k = self.propagate(edge_index=edge_index_norm[0], x=emb_k, norm=edge_index_norm[1])\n",
    "            embs.append(emb_k)\n",
    "            \n",
    "            \n",
    "        # this is doing the formula8 in LightGCN paper  \n",
    "            \n",
    "        # the stacked embs is a list of embedding matrix at each layer\n",
    "        #    it's of shape n_nodes x (n_layers + 1) x emb_vector_len. \n",
    "        #        e.g: torch.Size([10334, 4, 64])\n",
    "        embs = torch.stack(embs, dim=1)\n",
    "        \n",
    "        # From LightGCn paper: \"In our experiments, we find that setting α_k uniformly as 1/(K + 1)\n",
    "        #    leads to good performance in general.\"\n",
    "        emb_final = torch.mean(embs, dim=1) # E^K\n",
    "\n",
    "\n",
    "        # splits into e_u^K and e_i^K\n",
    "        users_emb_final, items_emb_final = torch.split(emb_final, [self.num_users, self.num_items]) \n",
    "\n",
    "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
    "        # here using .weight to get the tensor weights from n.Embedding\n",
    "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        # x_j is of shape:  edge_index_len x emb_vector_len\n",
    "        #    e.g: torch.Size([77728, 64]\n",
    "        #\n",
    "        # x_j is basically the embedding of all the neighbors based on the src_list in coo edge index\n",
    "        # \n",
    "        # elementwise multiply by the symmetrically norm. So it's essentiall what formula 7 in LightGCN\n",
    "        # paper does but here we are using edge_index rather than Adj Matrix\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "layers = 3    \n",
    "model = LightGCN(num_users=num_users, \n",
    "                 num_items=num_items, \n",
    "                 K=layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(users_emb_final, \n",
    "             users_emb_0, \n",
    "             pos_items_emb_final, \n",
    "             pos_items_emb_0, \n",
    "             neg_items_emb_final, \n",
    "             neg_items_emb_0, \n",
    "             lambda_val):\n",
    "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
    "\n",
    "    Args:\n",
    "        users_emb_final (torch.Tensor): e_u_k\n",
    "        users_emb_0 (torch.Tensor): e_u_0\n",
    "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
    "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
    "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
    "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
    "        lambda_val (float): lambda value for regularization loss term\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: scalar bpr loss value\n",
    "    \"\"\"\n",
    "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
    "                             pos_items_emb_0.norm(2).pow(2) +\n",
    "                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n",
    "\n",
    "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
    "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
    "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
    "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
    "\n",
    "\n",
    "    bpr_loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores))\n",
    "    \n",
    "    loss = bpr_loss + reg_loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_positive_items(edge_index):\n",
    "    \"\"\"\n",
    "    Generates dictionary of positive items for each user\n",
    "\n",
    "    Args:\n",
    "        edge_index (torch.Tensor): 2 by N list of edges \n",
    "\n",
    "    Returns:\n",
    "        dict: user -> list of positive items for each \n",
    "    \"\"\"\n",
    "    \n",
    "    # key: user_id, val: item_id list\n",
    "    user_pos_items = {}\n",
    "    \n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        \n",
    "        if user not in user_pos_items:\n",
    "            user_pos_items[user] = []\n",
    "        \n",
    "        user_pos_items[user].append(item)\n",
    "        \n",
    "    return user_pos_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes recall@K and precision@K\n",
    "def RecallPrecision_ATk(groundTruth, r, k):\n",
    "    \"\"\"Computers recall @ k and precision @ k\n",
    "\n",
    "    Args:\n",
    "        groundTruth (list[list[long]]): list of lists of item_ids. Cntaining highly rated items of each user. \n",
    "                            In other words, this is the list of true_relevant_items for each user\n",
    "                            \n",
    "        r (list[list[boolean]]): list of lists indicating whether each top k item recommended to each user\n",
    "                            is a top k ground truth (true relevant) item or not\n",
    "                            \n",
    "        k (int): determines the top k items to compute precision and recall on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of correctly predicted items per user\n",
    "    # -1 here means I want to sum at the inner most dimension\n",
    "    num_correct_pred = torch.sum(r, dim=-1)  \n",
    "    \n",
    "    # number of items liked by each user in the test set\n",
    "    user_num_liked = torch.Tensor([len(groundTruth[i]) for i in range(len(groundTruth))])\n",
    "    \n",
    "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
    "    precision = torch.mean(num_correct_pred) / k\n",
    "    return recall.item(), precision.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " #wrapper function to get evaluation metrics\n",
    "def get_metrics(model, \n",
    "                input_edge_index, # adj_mat based edge index\n",
    "                input_exclude_edge_indices, # adj_mat based exclude edge index\n",
    "                k):\n",
    "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
    "\n",
    "    Args:\n",
    "        model (LighGCN): lightgcn model\n",
    "        \n",
    "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
    "        \n",
    "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
    "        \n",
    "        k (int): determines the top k items to compute metrics on\n",
    "\n",
    "    Returns:\n",
    "        tuple: recall @ k, precision @ k, ndcg @ k\n",
    "    \"\"\"\n",
    "    # get the embedding tensor at layer 0 after training\n",
    "    user_embedding = model.users_emb.weight\n",
    "    item_embedding = model.items_emb.weight\n",
    "    \n",
    "\n",
    "    # convert adj_mat based edge index to r_mat based edge index so we have have \n",
    "    # the first list being user_ids and second list being item_ids for the edge index \n",
    "    edge_index = convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index)\n",
    "\n",
    "    # This is to exclude the edges we have seen before in our predicted interaction matrix (r_mat_rating)\n",
    "    # E.g: for validation set, we want want to exclude all the edges in training set\n",
    "    exclude_edge_indices = [convert_adj_mat_edge_index_to_r_mat_edge_index(exclude_edge_index) \\\n",
    "                                      for exclude_edge_index in input_exclude_edge_indices]\n",
    "\n",
    "     \n",
    "\n",
    "    # Generate predicted interaction matrix (r_mat_rating)    \n",
    "    # (num_users x 64) dot_product (num_item x 64).T \n",
    "    r_mat_rating = torch.matmul(user_embedding, item_embedding.T)\n",
    "    \n",
    "    # shape: num_users x num_item\n",
    "    rating = r_mat_rating\n",
    "   \n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        # gets all the positive items for each user from the edge index\n",
    "        # it's a dict: user -> positive item list\n",
    "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
    "        \n",
    "        # get coordinates of all edges to exclude\n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            # [user] * len(item) can give us [user1, user1, user1...] with len of len(item)\n",
    "            # this makes easier to do the masking below\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    "   \n",
    "        # set the excluded entry in the rat_mat_rating matrix to a very small number\n",
    "        rating[exclude_users, exclude_items] = -(1 << 10) \n",
    "\n",
    "    # get the top k recommended items for each user\n",
    "    _, top_K_items = torch.topk(rating, k=k)\n",
    "\n",
    "    # get all unique users in evaluated split\n",
    "    users = edge_index[0].unique()\n",
    "\n",
    "    # dict of user -> pos_item list\n",
    "    test_user_pos_items = get_user_positive_items(edge_index)\n",
    "\n",
    "    # convert test user pos items dictionary into a list of lists\n",
    "    test_user_pos_items_list = [test_user_pos_items[user.item()] for user in users]\n",
    "\n",
    "\n",
    "    # r here is \"pred_relevant_items ∩ actually_relevant_items\" list for each user\n",
    "    r = []\n",
    "    for user in users:\n",
    "        user_true_relevant_item = test_user_pos_items[user.item()]\n",
    "        # list of Booleans to store whether or not a given item in the top_K_items for a given user \n",
    "        # is also present in user_true_relevant_item.\n",
    "        # this is later on used to compute n_rel_and_rec_k\n",
    "        label = list(map(lambda x: x in user_true_relevant_item, top_K_items[user]))\n",
    "        r.append(label)\n",
    "        \n",
    "    r = torch.Tensor(np.array(r).astype('float'))\n",
    "\n",
    "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
    "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
    "\n",
    "    return recall, precision, ndcg"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f658235f33a66d20b962167037a25a33691ada8426c14e9defd38a29d6fbf2b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('3.9.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
